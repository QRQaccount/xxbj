# Core组件的高级特性

## 如何处理图像中的像素

### 图像在内存中的储存方式

矩阵的大小取决于所用的颜色模型，更准确的来说是通道数。![](/media/qrq/QRQ SD/学习笔记/图像处理/image/灰度图像矩阵模型.png)

而对于多通道来讲，每一列会包含过个子列，如常用的RGB颜色模型![](/media/qrq/QRQ SD/学习笔记/图像处理/image/rgb矩阵模型.png)

当内存足够大时，会使用连续储存，其中的图像就能一行行的连接起来形成一个长行。可以使用isContinuous()来判断是否为连续储存。

### 颜色空间缩减

过多的颜色组合会对算法性能造成严重影响。仅使用其中的一些具有代表性的部分就能达到同样的效果。此时就使用颜色空间缩减，及将某一个范围的颜色归到一类中。利用c++的类型的自动省略完场这个步骤,对图像矩阵中的每一个元素执行这个函数I<sub>new</sub> = (I<sub>old</sub> / 10) * 10

### LUT函数

### 计时函数

两个函数getTickCount(),getTickFrequency()函数。前者记录cpu自某个时间后走过时间周期数，后者返回cpu一秒所走的时间周期数。

```cpp
//输出运行时间     
double time0 = static_cast<double>(getTickCount());
//图像处理的中间过程
time0 = ((double)getTickCount() - time0) / getTickFrequency();
```

### 访问图像中的像素的三种方式

三者速度由快到慢

1. 使用指针访问
   
   1. 使用二重循环逐个访问像素，其中列数为图像像素列数*通道数，行数为图像像素行数。利用ptr函数返回一行的头指针。利用channels()返回通道数
   
   2. ```cpp
      int colsNum = A.cols * A.channels(); //获取列数 = 像素数量 * 通道数量
      
           int rowsNum = A.rows; //获取行数
           for (int i = 0; i < rowsNum; i++)
           {
                uchar *data = A.ptr<uchar>(i);
                for (int j = 0; j < colsNum; j++)
                {
                     data[j] = (data[j] / 32) * 32 + 16;
                }
           }
      ```

2. 使用迭代器进行访问，访问方式与STL库的使用方式相同 
   
   1. ```cpp
           Mat_<Vec3b>::iterator begin = A.begin<Vec3b>();
           Mat_<Vec3b>::iterator end = A.end<Vec3b>();
           while (begin != end)
           {
                (*begin)[0] = (*begin)[0] / 10 * 10 + 5;
                (*begin)[1] = (*begin)[1] / 10 * 10 + 5;
                (*begin)[2] = (*begin)[2] / 10 * 10 + 5;
                begin++;
           }
      ```

3. 使用动态地址计算
   
   1. 获取Mat的行列数之后，通过at\<Vec3b>(row,col)[n]来获取所选取的通道
   
   2. ```cpp
           int row = A.rows;
           int col = A.cols;
           for (int i = 0; i < row; i++)
           {
                for (int j = 0; j < col; j++)
                {
                     A.at<Vec3b>(i, j)[0] = A.at<Vec3b>(i, j)[0] / 10 * 10 + 5;
                     A.at<Vec3b>(i, j)[1] = A.at<Vec3b>(i, j)[1] / 10 * 10 + 5;
                     A.at<Vec3b>(i, j)[2] = A.at<Vec3b>(i, j)[2] / 10 * 10 + 5;
                }
           }
      ```

## 感兴趣区域ROI

### 获取ROI

在图像处理时，我们需要选择读取需要专门处理的区域。指定特定的读入目标，可以减少处理时间，增加精度，两种读取的方式

1. 使用Rect指定矩形的读取区域

2. 使用Range()来表示索引的范围

3. ```cpp
        Mat A = imread("1.jpg");
        Mat b, c;
        b = A(Rect(60, 60, 40, 40));
        c = A(Range(100, 140), Range(30, 100));
   ```

### 线性混合

通过在范围0到1的alpha值来对两张图片进行混合,理论公式如下
$$
g(x) = (1-\alpha)f_0(x)+\alpha{f_1(x)}
$$

### 计算数组加权和

使用函数 void addWeighted(InputArray src1, double alpha, InputArray src2,double beta, double gamma, OutputArray dst, int dtype = -1);来进行加权混合

1. 参数
   1. src1第一个输入图像
   2. alpha 第一个图像元素的alpha权重
   3. src2 第二个输入图像，其大小和通道数量与src1相同
   4. beta 第二个数组元素的权重
   5. gamma 标量添加到每个总和
   6. dst 输出图像，其大小和通道数与输入数组相同
   7. dtype 输出图像的可选[深度](https://juejin.im/post/5d06e4e7f265da1b971a7438); 当两个输入数组都具有相同的深度时，dtype可以设置为-1，这相当于src1.depth()

## 分离颜色通道以及多通道图像混合

为了更好的对图像的一些特征进行处理，需要将RGB三个颜色的通道分量进行分别显示和调整。主要使用splite()和merge()函数

1. 通道分离函数split()
   
   1. 第一 个参数是输入的图像Mat类型或是InputArray类型
   
   2. 第二个参数是一个指向一个Mat型数组(或是vector)或者一个OutputArrayOfArrays类型(本质为一个OutputArray的引用)，自动将通道分离
   
   3. ```cpp
           Mat mats[3];
           split(A, mats);
           Mat B = mats[0];
           Mat G = mats[1];
           Mat R = mats[2];
      ```

2. 通道合并函数merge()
   
   1. 输入的矩阵数组
   2. 如果为c形式的数组，需要传入数组的元素个数
   3. 合并输出的矩阵

3. 例子
   
   ```cpp
   #include <opencv2/opencv.hpp>
   #include <opencv2/highgui/highgui.hpp>
   #include <vector>
   using namespace std;
   using namespace cv;
   int main(int argc, char const *argv[])
   {
        Mat A = imread("1.jpg");
        vector<Mat> mats;
        // Mat mats[3];
        split(A, mats);
        Mat B = mats[0];
        Mat G = mats[1];
        Mat R = mats[2];
        imshow("B", B);
        imshow("G", G);
        imshow("R", R);
        Mat all;
        merge(mats, all);
        // merge(mats, 3, all);
        imshow("all", all);
        waitKey();
        return 0;
   }
   ```

## 图像对比度，亮度值调整

一般图像处理算子都是一个函数，它接受一个或者多个输入图像，并输出图像。图像对比度和亮度的调节属于图像处理中的点操作

> 点操作是对仅当前一个像素点的信息进行处理输出处理后结果，常用的操作有亮度，对比度，颜色矫正，变换

理论依据:
$$
g(i,j) = a*{f(i,j)} +b
$$

- f(i,j)为输入的像素点
- g(i,j)为输出的像素点
- a(a>0),被称为增益(gain)，常常用于控制图像的对比度
- b被称为偏置，用于控制图像亮度

## 离散傅里叶变换

离散傅里叶变换(DFT)是指，将时域信号采样变换为在离散时间傅里叶变化采样

### 离散傅里叶变化的原理

简单的来说，图像的傅里叶变换是将它分解成正弦和余弦两个部分。从空间域转到频域
$$
F(k,l) = \sum_{i=0}^{N-1}\sum_{j=0}^{N-1}f(i,j)e^{-i2\pi(\frac{ki}{N}+\frac{lj}{N})}
$$

$$
e^{ix} = cosx+isinx
$$

其中f是空间域值F是频域值。转换后的频域值为复数。所以显示傅里叶变换后的结果需要实属图像+虚数图像或是幅度图像+相位图像。<br>对于一个图像，高频存放了图像的细节，纹理信息。低频部分储存了图像的轮廓信息。

### 例子

```cpp

#include "opencv2/core/core.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include "opencv2/highgui/highgui.hpp"
#include <iostream>
using namespace cv;

int main()
{

     //【1】以灰度模式读取原始图像并显示
     Mat srcImage = imread("illust_35969353_20190523_231042.jpg", 0);
     if (!srcImage.data)
     {
          printf("读取图片错误，请确定目录下是否有imread函数指定图片存在~！ \n");
          return false;
     }
     imshow("原始图像", srcImage);

     //【2】将输入图像延扩到最佳的尺寸，边界用0补充
     int m = getOptimalDFTSize(srcImage.rows);
     int n = getOptimalDFTSize(srcImage.cols);
     //将添加的像素初始化为0.
     Mat padded;
     copyMakeBorder(srcImage, padded, 0, m - srcImage.rows, 0, n - srcImage.cols, BORDER_CONSTANT, Scalar::all(0));

     //【3】为傅立叶变换的结果(实部和虚部)分配存储空间。
     //将planes数组组合合并成一个多通道的数组complexI
     Mat planes[] = {Mat_<float>(padded), Mat::zeros(padded.size(), CV_32F)};
     Mat complexI;
     merge(planes, 2, complexI);

     //【4】进行就地离散傅里叶变换
     dft(complexI, complexI);

     //【5】将复数转换为幅值，即=> log(1 + sqrt(Re(DFT(I))^2 + Im(DFT(I))^2))
     split(complexI, planes);                    // 将多通道数组complexI分离成几个单通道数组，planes[0] = Re(DFT(I), planes[1] = Im(DFT(I))
     magnitude(planes[0], planes[1], planes[0]); // planes[0] = magnitude用于计算二维矢量的幅值
     Mat magnitudeImage = planes[0];

     //【6】进行对数尺度(logarithmic scale)缩放
     magnitudeImage += Scalar::all(1);
     log(magnitudeImage, magnitudeImage); //求自然对数

     //【7】剪切和重分布幅度图象限
     //若有奇数行或奇数列，进行频谱裁剪
     magnitudeImage = magnitudeImage(Rect(0, 0, magnitudeImage.cols & -2, magnitudeImage.rows & -2));
     //重新排列傅立叶图像中的象限，使得原点位于图像中心
     int cx = magnitudeImage.cols / 2;
     int cy = magnitudeImage.rows / 2;
     Mat q0(magnitudeImage, Rect(0, 0, cx, cy));   // ROI区域的左上
     Mat q1(magnitudeImage, Rect(cx, 0, cx, cy));  // ROI区域的右上
     Mat q2(magnitudeImage, Rect(0, cy, cx, cy));  // ROI区域的左下
     Mat q3(magnitudeImage, Rect(cx, cy, cx, cy)); // ROI区域的右下
     //交换象限（左上与右下进行交换）
     Mat tmp;
     q0.copyTo(tmp);
     q3.copyTo(q0);
     tmp.copyTo(q3);
     //交换象限（右上与左下进行交换）
     q1.copyTo(tmp);
     q2.copyTo(q1);
     tmp.copyTo(q2);

     //【8】归一化，用0到1之间的浮点值将矩阵变换为可视的图像格式
     //此句代码的OpenCV2版为：
     //normalize(magnitudeImage, magnitudeImage, 0, 1, CV_MINMAX);
     //此句代码的OpenCV3版为:
     normalize(magnitudeImage, magnitudeImage, 0, 1, NORM_MINMAX);

     //【9】显示效果图
     imshow("频谱幅值", magnitudeImage);
     waitKey();

     return 0;
}
```
